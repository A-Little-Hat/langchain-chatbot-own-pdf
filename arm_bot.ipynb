{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain. vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "DB_FAISS_PATH = \"vectorstores/db_faiss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load document and create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-12 20:13:37 - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(DATA_PATH, glob='*.pdf', loader_cls=PyPDFLoader)\n",
    "documents = loader. load( )\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "model_kwargs = {'device': 'cpu'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(texts,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model load and test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain. llms import CTransformers\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, please just say that you don't know the answer, don't try to make up\n",
    "an answer. \n",
    "Context: {context}\n",
    "Question: {question}. \n",
    "Only returns the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_prompt():\n",
    "    prompt = PromptTemplate(template=custom_prompt_template, input_variables=['context','question'])\n",
    "    return prompt\n",
    "\n",
    "def load_llm():\n",
    "    llm = CTransformers(\n",
    "    model = \"llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "    model_type = \"llama\",\n",
    "    max_new_tokens = 512,\n",
    "    temperature = 0.1)\n",
    "\n",
    "    return llm\n",
    "\n",
    "\n",
    "def retrieval_qa_chain(llm, prompt, db):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = db.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents = True,\n",
    "    chain_type_kwargs = {'prompt': prompt})\n",
    "\n",
    "    return qa_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-12 20:19:04 - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': 'cpu'})\n",
    "db = FAISS. load_local(DB_FAISS_PATH, embeddings)\n",
    "llm = load_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_bot():\n",
    "    qa_prompt = set_custom_prompt()\n",
    "    qa = retrieval_qa_chain(llm, qa_prompt, db)\n",
    "\n",
    "    return qa\n",
    "\n",
    "def final_result(query):\n",
    "    qa_result = qa_bot()\n",
    "    response = qa_result({'query': query})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=final_result(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is arm?',\n",
       " 'result': 'Arm is a computer architecture and instruction set that is widely used in microprocessors, microcontrollers, and other digital circuits. It was developed by Arm Limited (formerly Acorn Computers Limited), a British company that was acquired by SoftBank Group in 2016. The Arm architecture is designed to be efficient in terms of power consumption and cost, making it well-suited for use d for use in gged for aited for aited for embedded systems such applications such ased in gged for embedded systems thated inited for use inated for mobile devices such applications such applications such applications such applications such applications such ased in tol tted for use d for use d for use dited for embedding into aited for use d for embedded systems such ased ined ined inied for aited for use d for use d for aited for aited for use d for use for embedded systems that for embedded systems where small and for mobile devices thatched forted for battery forged for use in gested for use inited for use d for use d for use inited for use d for use d for use d for use d for embedding into many applications such ased in for use inited for',\n",
       " 'source_documents': [Document(page_content='Introducing the Arm architecture  ARM062 -948681440 -3277  \\n \\n \\nCopyright Â© 2019 Arm Limited (or its affiliates). All rights reserved.  \\nNon-Confidential  \\nPage 3 of 19 \\n 110 Fulbourn Road, Cambridge, England CB1 9NJ.  \\nConfidentiality Status  \\nThis document is Non- Confidential. The right to use, copy and disclose this document may be subject to license restrictions in \\naccordance with the terms of the agreement entered into b y Arm and the party that Arm delivered this document to.  \\nUnrestricted Access is an Arm internal classification.  \\nProduct Status  \\nThe information in this document is Final, that is for a developed product.  \\nWeb Address  \\n33Thttp://www.arm.com 33T', metadata={'source': 'data\\\\Introducing the Arm architecture.pdf', 'page': 2}),\n",
       "  Document(page_content='We have discussed some of the common terms and concepts that are key to understanding the Arm architecture, and the different  \\nprofiles of the Arm architecture. We have described features that are specific to architecture and micro -architecture, and how Arm \\narchitecture terms and concepts appear in Arm architecture reference manuals (Arm ARMs) and other Arm documentation and resources. We have also l earned about the different profiles of the Arm architecture and other Arm architectures.  \\nFurther guides in this series introduce aspects of the Arm architecture in detail, and provide examples and commentary.  \\nTo keep learning about the Armv8 -A architecture , see more in our series of guides .', metadata={'source': 'data\\\\Introducing the Arm architecture.pdf', 'page': 18})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
